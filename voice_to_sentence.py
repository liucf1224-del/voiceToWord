import os

import moviepy
# import moviepy.editor as mp
import whisper
from pydub import AudioSegment
from pydub.silence import split_on_silence
import re


def extract_audio_from_video(video_path, audio_output_path):
    """
    ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘ã€‚
    """
    try:
        # video = mp.VideoFileClip(video_path)
        video =  moviepy.VideoFileClip(video_path)
        video.audio.write_audiofile(
            audio_output_path,
            fps=16000,
            nbytes=2,
            codec="pcm_s16le"
        )
        print(f"éŸ³é¢‘å·²æˆåŠŸæå–åˆ°: {audio_output_path}")
        return True
    except Exception as e:
        print(f"æå–éŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


def transcribe_audio_with_whisper(audio_path, model_name="base", device=None, cache_dir=None):
    """
    ä½¿ç”¨ OpenAI Whisper æ¨¡å‹å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ã€‚
    model_name å¯ä»¥æ˜¯ "tiny", "base", "small", "medium", "large"ã€‚
    æ›´å¤§çš„æ¨¡å‹å‡†ç¡®åº¦æ›´é«˜ï¼Œä½†éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚
    """
    try:
        if device is None:
            try:
                import torch
                device = "cuda" if torch.cuda.is_available() else "cpu"
            except Exception:
                device = "cpu"
        print(f"æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹: {model_name}...")
        model = whisper.load_model(model_name, device=device, download_root=cache_dir)
        print(f"æ­£åœ¨è½¬å½•éŸ³é¢‘: {audio_path}...")
        fp16_run = device != "cpu"
        result = model.transcribe(audio_path, fp16=fp16_run)
        return result["text"]
    except Exception as e:
        print(f"è½¬å½•éŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


def split_and_transcribe_audio(audio_path, output_dir="audio_chunks", min_silence_len=500, silence_thresh=-40,
                               model_name="base", device=None, cache_dir=None):
    """
    å°†éŸ³é¢‘æ–‡ä»¶åˆ†å‰²æˆå°å—ï¼Œç„¶åé€å—è½¬å½•ã€‚
    è¿™å¯¹äºé•¿éŸ³é¢‘æ–‡ä»¶æˆ–å†…å­˜å—é™çš„æƒ…å†µéå¸¸æœ‰ç”¨ã€‚
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    try:
        audio = AudioSegment.from_file(audio_path)
        chunks = split_on_silence(audio,
                                  min_silence_len=min_silence_len,  # è¯†åˆ«ä¸ºé™éŸ³çš„æœ€å°é•¿åº¦ (æ¯«ç§’)
                                  silence_thresh=silence_thresh,  # ä½äºæ­¤åˆ†è´å€¼çš„è¢«è®¤ä¸ºæ˜¯é™éŸ³
                                  keep_silence=200  # ä¿ç•™é™éŸ³çš„å‰å200æ¯«ç§’
                                  )

        full_text = []
        if device is None:
            try:
                import torch
                device = "cuda" if torch.cuda.is_available() else "cpu"
            except Exception:
                device = "cpu"
        model = whisper.load_model(model_name, device=device, download_root=cache_dir)
        print(f"æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹: {model_name}...")

        for i, chunk in enumerate(chunks):
            chunk_filename = os.path.join(output_dir, f"chunk_{i}.wav")
            chunk.export(chunk_filename, format="wav")
            print(f"æ­£åœ¨è½¬å½•åˆ†å— {i + 1}/{len(chunks)}: {chunk_filename}")

            # ä½¿ç”¨ Whisper è½¬å½•æ¯ä¸ªåˆ†å—
            fp16_run = device != "cpu"
            result = model.transcribe(chunk_filename, fp16=fp16_run)
            text = result["text"]
            full_text.append(text)
            print(f"åˆ†å— {i + 1} è½¬å½•å®Œæˆã€‚")

            # ç«‹å³åˆ é™¤å·²å¤„ç†çš„åˆ†å—æ–‡ä»¶ä»¥èŠ‚çœç©ºé—´
            try:
                os.remove(chunk_filename)
                print(f"âœ“ å·²åˆ é™¤åˆ†å—æ–‡ä»¶: {chunk_filename}")
            except Exception as e:
                print(f"âš ï¸  åˆ é™¤åˆ†å—æ–‡ä»¶æ—¶å‡ºé”™: {e}")

        return " ".join(full_text)
    except Exception as e:
        print(f"åˆ†æ®µå’Œè½¬å½•éŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None


def get_filename_without_extension(file_path):
    """
    è·å–æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åå’Œè·¯å¾„ï¼‰
    """
    base_name = os.path.basename(file_path)  # è·å–æ–‡ä»¶åï¼ˆåŒ…å«æ‰©å±•åï¼‰
    filename_without_ext = os.path.splitext(base_name)[0]  # å»é™¤æ‰©å±•å
    return filename_without_ext


def _apply_ml_punctuation(text, cache_dir=None):
    try:
        if cache_dir:
            os.makedirs(cache_dir, exist_ok=True)
            os.environ["HF_HOME"] = cache_dir
            os.environ["HUGGINGFACE_HUB_CACHE"] = os.path.join(cache_dir, "hub")
        from dbpunctuator.inference import Inference, InferenceArguments
        from dbpunctuator.utils import DEFAULT_CHINESE_TAG_PUNCTUATOR_MAP
        args = InferenceArguments(
            model_name_or_path="Qishuai/distilbert_punctuator_zh",
            tokenizer_name="Qishuai/distilbert_punctuator_zh",
            tag2punctuator=DEFAULT_CHINESE_TAG_PUNCTUATOR_MAP
        )
        punctuator = Inference(args)
        res = punctuator.punctuation(text)
        if isinstance(res, str):
            return res
        if isinstance(res, tuple) and len(res) >= 2:
            tokens, tags = res[0], res[1]
            def _norm_tag(t):
                while isinstance(t, list) and len(t) > 0:
                    t = t[0]
                if isinstance(t, (list, tuple)) and len(t) == 0:
                    return None
                if isinstance(t, (int, float)):
                    return str(int(t))
                if t is None:
                    return None
                return str(t)
            local_map = {
                "COMMA": "ï¼Œ", "PERIOD": "ã€‚", "QUESTION": "ï¼Ÿ", "EXCLAMATION": "ï¼",
                "comma": "ï¼Œ", "period": "ã€‚", "question": "ï¼Ÿ", "exclamation": "ï¼",
                "B-COMMA": "ï¼Œ", "B-PERIOD": "ã€‚", "B-QUESTION": "ï¼Ÿ", "B-EXCLAMATION": "ï¼",
                ",": "ï¼Œ", ".": "ã€‚", "?": "ï¼Ÿ", "!": "ï¼",
                "1": "ï¼Œ", "2": "ã€‚", "3": "ï¼Ÿ", "4": "ï¼"
            }
            mapping = DEFAULT_CHINESE_TAG_PUNCTUATOR_MAP or local_map
            buf = []
            out = []
            for tk, tg in zip(tokens, tags):
                s = str(tk).strip()
                if not s:
                    continue
                s = s.replace("ã€‚", "").replace("ï¼Œ", "").replace("ï¼", "").replace("ï¼Ÿ", "").replace(".", "").replace("!", "").replace("?", "")
                if s:
                    buf.append(s)
                nt = _norm_tag(tg)
                punct = mapping.get(nt)
                if isinstance(punct, str) and punct:
                    if punct in [",", "ï¼Œ"]:
                        buf.append("ï¼Œ")
                    else:
                        end = "ã€‚" if punct == "." else punct
                        out.append("".join(buf) + end)
                        buf = []
            if buf:
                out.append("".join(buf))
            punct_text = "".join(out)
            if not re.search(r"[ï¼Œã€‚,\.ï¼Ÿï¼?!]", punct_text):
                tmp = text
                tmp = re.sub(r"(ä»€éº¼|ä»€ä¹ˆ|å—|å—)(?![ã€‚ï¼Ÿï¼?!])", r"\1ã€‚", tmp)
                if not re.search(r"[ã€‚\.ï¼Ÿï¼?!]$", tmp):
                    tmp = tmp + "ã€‚"
                return tmp
            return punct_text
        if isinstance(res, tuple) and len(res) >= 1:
            tokens = res[0]
            if isinstance(tokens, list):
                tmp = "".join(tokens)
                if not re.search(r"[ï¼Œã€‚,\.ï¼Ÿï¼?!]", tmp):
                    tmp = re.sub(r"(ä»€éº¼|ä»€ä¹ˆ|å—|å—)(?![ã€‚ï¼Ÿï¼?!])", r"\1ã€‚", tmp)
                    if not re.search(r"[ã€‚\.ï¼Ÿï¼?!]$", tmp):
                        tmp = tmp + "ã€‚"
                return tmp
            if isinstance(tokens, str):
                tmp = tokens
                if not re.search(r"[ï¼Œã€‚,\.ï¼Ÿï¼?!]", tmp):
                    tmp = re.sub(r"(ä»€éº¼|ä»€ä¹ˆ|å—|å—)(?![ã€‚ï¼Ÿï¼?!])", r"\1ã€‚", tmp)
                    if not re.search(r"[ã€‚\.ï¼Ÿï¼?!]$", tmp):
                        tmp = tmp + "ã€‚"
                return tmp
        s = str(res)
        if not re.search(r"[ï¼Œã€‚,\.ï¼Ÿï¼?!]", s):
            s = re.sub(r"(ä»€éº¼|ä»€ä¹ˆ|å—|å—)(?![ã€‚ï¼Ÿï¼?!])", r"\1ã€‚", s)
            if not re.search(r"[ã€‚\.ï¼Ÿï¼?!]$", s):
                s = s + "ã€‚"
        return s
    except Exception as e:
        print(f"æ ‡ç‚¹æ¢å¤å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹æ–‡æœ¬: {e}")
        return None


def process_audio_to_text(audio_path, model_name="base", use_segmentation=False, model_cache_dir=None, use_ml_punctuation=False, ml_cache_dir=None):
    if not os.path.exists(audio_path):
        print(f"é”™è¯¯ï¼šéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        return False
    audio_name = get_filename_without_extension(audio_path)
    text_output_file = f"{audio_name}.txt"
    print(f"æ­£åœ¨å¤„ç†éŸ³é¢‘: {audio_path}")
    print(f"è¾“å‡ºæ–‡æœ¬æ–‡ä»¶å°†ä¿å­˜ä¸º: {text_output_file}")
    transcribed_text = None
    if use_segmentation:
        print("\n--- æ­£åœ¨ä½¿ç”¨åˆ†æ®µè½¬å½• ---")
        transcribed_text = split_and_transcribe_audio(
            audio_path,
            output_dir=f"{audio_name}_audio_chunks",
            min_silence_len=700,
            silence_thresh=-35,
            model_name=model_name,
            cache_dir=model_cache_dir
        )
    else:
        print("\n--- æ­£åœ¨ä½¿ç”¨ç›´æ¥è½¬å½• ---")
        transcribed_text = transcribe_audio_with_whisper(audio_path, model_name=model_name, cache_dir=model_cache_dir)
    if use_ml_punctuation and transcribed_text:
        print("\n--- æ­£åœ¨æ¢å¤æ–‡æœ¬æ ‡ç‚¹ ---")
        punctuated_text = _apply_ml_punctuation(transcribed_text, cache_dir=ml_cache_dir)
        if punctuated_text:
            transcribed_text = punctuated_text
    if transcribed_text:
        print("\n--- è½¬å½•å®Œæˆ ---")
        print("è½¬å½•ç»“æœé¢„è§ˆ:")
        print(transcribed_text[:200] + "..." if len(transcribed_text) > 200 else transcribed_text)
        try:
            with open(text_output_file, "w", encoding="utf-8") as f:
                f.write(transcribed_text)
            print(f"\nè½¬å½•æ–‡æœ¬å·²æˆåŠŸä¿å­˜åˆ°: {text_output_file}")
        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    else:
        print("è½¬å½•å¤±è´¥ã€‚")
        return False
    try:
        if use_segmentation:
            chunks_dir = f"{audio_name}_audio_chunks"
            if os.path.exists(chunks_dir):
                import shutil
                shutil.rmtree(chunks_dir)
                print(f"å·²åˆ é™¤ä¸´æ—¶éŸ³é¢‘åˆ†å—ç›®å½•: {chunks_dir}")
    except Exception as e:
        print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‘ç”Ÿè­¦å‘Š: {e}")
    return True


def process_video_to_text(video_path, model_name="base", use_segmentation=False, model_cache_dir=None, use_ml_punctuation=False, ml_cache_dir=None):
    """
    å¤„ç†è§†é¢‘æ–‡ä»¶ï¼Œæå–éŸ³é¢‘å¹¶è½¬å½•ä¸ºæ–‡æœ¬

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        model_name: Whisperæ¨¡å‹åç§° ("tiny", "base", "small", "medium", "large")
        use_segmentation: æ˜¯å¦ä½¿ç”¨åˆ†æ®µè½¬å½•ï¼ˆæ¨èç”¨äºé•¿è§†é¢‘ï¼‰
    """
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return False

    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    video_name = get_filename_without_extension(video_path)
    audio_file = f"{video_name}_temp_audio.wav"  # ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ï¼ˆWAVï¼Œä¾¿äºè¯­éŸ³è¯†åˆ«ï¼‰
    text_output_file = f"{video_name}.txt"  # è¾“å‡ºæ–‡æœ¬æ–‡ä»¶

    print(f"æ­£åœ¨å¤„ç†è§†é¢‘: {video_path}")
    print(f"è¾“å‡ºæ–‡æœ¬æ–‡ä»¶å°†ä¿å­˜ä¸º: {text_output_file}")

    # 1. ä»è§†é¢‘ä¸­æå–éŸ³é¢‘
    if not extract_audio_from_video(video_path, audio_file):
        print("éŸ³é¢‘æå–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å¤„ç†ã€‚")
        return False

    # 2. è½¬å½•éŸ³é¢‘
    transcribed_text = None

    if use_segmentation:
        print("\n--- æ­£åœ¨ä½¿ç”¨åˆ†æ®µè½¬å½• ---")
        transcribed_text = split_and_transcribe_audio(
            audio_file,
            output_dir=f"{video_name}_audio_chunks",
            min_silence_len=700,
            silence_thresh=-35,
            model_name=model_name,
            cache_dir=model_cache_dir
        )
    else:
        print("\n--- æ­£åœ¨ä½¿ç”¨ç›´æ¥è½¬å½• ---")
        transcribed_text = transcribe_audio_with_whisper(audio_file, model_name=model_name, cache_dir=model_cache_dir)
    if use_ml_punctuation and transcribed_text:
        print("\n--- æ­£åœ¨æ¢å¤æ–‡æœ¬æ ‡ç‚¹ ---")
        punctuated_text = _apply_ml_punctuation(transcribed_text, cache_dir=ml_cache_dir)
        if punctuated_text:
            transcribed_text = punctuated_text

    # 3. ä¿å­˜è½¬å½•ç»“æœ
    if transcribed_text:
        print("\n--- è½¬å½•å®Œæˆ ---")
        print("è½¬å½•ç»“æœé¢„è§ˆ:")
        print(transcribed_text[:200] + "..." if len(transcribed_text) > 200 else transcribed_text)

        try:
            with open(text_output_file, "w", encoding="utf-8") as f:
                f.write(transcribed_text)
            print(f"\nè½¬å½•æ–‡æœ¬å·²æˆåŠŸä¿å­˜åˆ°: {text_output_file}")
        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    else:
        print("è½¬å½•å¤±è´¥ã€‚")
        return False

    # 4. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try:
        if os.path.exists(audio_file):
            os.remove(audio_file)
            print(f"å·²åˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {audio_file}")

        # å¦‚æœä½¿ç”¨äº†åˆ†æ®µè½¬å½•ï¼Œæ¸…ç†åˆ†å—ç›®å½•
        if use_segmentation:
            chunks_dir = f"{video_name}_audio_chunks"
            if os.path.exists(chunks_dir):
                import shutil
                shutil.rmtree(chunks_dir)
                print(f"å·²åˆ é™¤ä¸´æ—¶éŸ³é¢‘åˆ†å—ç›®å½•: {chunks_dir}")
    except Exception as e:
        print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‘ç”Ÿè­¦å‘Š: {e}")

    return True


# --- ä¸»è¦æ‰§è¡Œéƒ¨åˆ† ---
if __name__ == "__main__":
    print("è¯·é€‰æ‹©è¾“å…¥ç±»å‹:")
    print("1. è§†é¢‘æ–‡ä»¶")
    print("2. éŸ³é¢‘æ–‡ä»¶")
    input_choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2ï¼Œé»˜è®¤ä¸º1): ").strip()
    is_video = input_choice != "2"
    path = input("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„: ").strip().strip('"\'')

    if not path:
        print("é”™è¯¯ï¼šæœªæä¾›æ–‡ä»¶è·¯å¾„")
        exit(1)

    print("\nå¯ç”¨çš„Whisperæ¨¡å‹:")
    print("1. tiny - æœ€å¿«ï¼Œå‡†ç¡®åº¦æœ€ä½")
    print("2. base - å¹³è¡¡é€Ÿåº¦å’Œå‡†ç¡®åº¦ï¼ˆæ¨èï¼‰")
    print("3. small - è¾ƒå¥½å‡†ç¡®åº¦")
    print("4. medium - é«˜å‡†ç¡®åº¦")
    print("5. large - æœ€é«˜å‡†ç¡®åº¦ï¼Œéœ€è¦æ›´å¤šèµ„æº")

    model_choice = input("\nè¯·é€‰æ‹©æ¨¡å‹ (1-5ï¼Œé»˜è®¤ä¸º2): ").strip()

    model_map = {
        "1": "tiny",
        "2": "base",
        "3": "small",
        "4": "medium",
        "5": "large"
    }

    selected_model = model_map.get(model_choice, "base")
    print(f"å·²é€‰æ‹©æ¨¡å‹: {selected_model}")

    segmentation_choice = input("\næ˜¯å¦ä½¿ç”¨åˆ†æ®µè½¬å½•ï¼Ÿ(é€‚åˆé•¿éŸ³é¢‘/é•¿è§†é¢‘ï¼Œy/N): ").strip().lower()
    use_segmentation = segmentation_choice in ['y', 'yes', 'æ˜¯']

    default_cache = os.path.join(os.getcwd(), ".whisper_cache")
    use_default_cache = input(f"\næ˜¯å¦ä½¿ç”¨æœ¬åœ°ç¼“å­˜ç›®å½• {default_cache}ï¼Ÿ(y/N): ").strip().lower()
    model_cache_dir = None
    if use_default_cache in ['y', 'yes', 'æ˜¯']:
        if not os.path.exists(default_cache):
            os.makedirs(default_cache, exist_ok=True)
        model_cache_dir = default_cache
    else:
        custom_cache = input("è¯·è¾“å…¥è‡ªå®šä¹‰ç¼“å­˜ç›®å½•ï¼ˆç•™ç©ºä¸ºç³»ç»Ÿé»˜è®¤ï¼‰: ").strip().strip('"\'')
        if custom_cache:
            if not os.path.exists(custom_cache):
                os.makedirs(custom_cache, exist_ok=True)
            model_cache_dir = custom_cache
    ml_punct_choice = input("\næ˜¯å¦ä½¿ç”¨DistilBERTæ ‡ç‚¹æ¢å¤ï¼Ÿ(y/N): ").strip().lower()
    use_ml_punctuation = ml_punct_choice in ['y', 'yes', 'æ˜¯']
    ml_default_cache = os.path.join(os.getcwd(), ".hf_cache")
    ml_use_default_cache = input(f"\næ˜¯å¦ä½¿ç”¨DistilBERTæœ¬åœ°ç¼“å­˜ç›®å½• {ml_default_cache}ï¼Ÿ(y/N): ").strip().lower()
    ml_cache_dir = None
    if ml_use_default_cache in ['y', 'yes', 'æ˜¯']:
        if not os.path.exists(ml_default_cache):
            os.makedirs(ml_default_cache, exist_ok=True)
        ml_cache_dir = ml_default_cache
    else:
        ml_custom_cache = input("è¯·è¾“å…¥DistilBERTè‡ªå®šä¹‰ç¼“å­˜ç›®å½•ï¼ˆç•™ç©ºä¸ºç³»ç»Ÿé»˜è®¤ï¼‰: ").strip().strip('\"\'')
        if ml_custom_cache:
            if not os.path.exists(ml_custom_cache):
                os.makedirs(ml_custom_cache, exist_ok=True)
            ml_cache_dir = ml_custom_cache

    if is_video:
        success = process_video_to_text(
            video_path=path,
            model_name=selected_model,
            use_segmentation=use_segmentation,
            model_cache_dir=model_cache_dir,
            use_ml_punctuation=use_ml_punctuation,
            ml_cache_dir=ml_cache_dir
        )
    else:
        success = process_audio_to_text(
            audio_path=path,
            model_name=selected_model,
            use_segmentation=use_segmentation,
            model_cache_dir=model_cache_dir,
            use_ml_punctuation=use_ml_punctuation,
            ml_cache_dir=ml_cache_dir
        )

    if success:
        print("\nğŸ‰ è½¬å½•å®Œæˆï¼")
    else:
        print("\nâŒ è½¬å½•å¤±è´¥ã€‚")
    try:
        import sys
        sys.stdout.flush()
    except Exception:
        pass
    os._exit(0 if success else 1)
